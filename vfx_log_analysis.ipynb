{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZbqlT-TSV-9",
        "outputId": "9f686e8f-c4fc-431a-d50b-2bd40b63911e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš¨ Long tasks: 0, Failed tasks: 236\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "os.makedirs(\"plots\", exist_ok=True)\n",
        "\n",
        "# Load JSON data\n",
        "\n",
        "with open(\"vfx_logs.json\") as f:\n",
        "    logs = json.load(f)\n",
        "\n",
        "df = pd.json_normalize(logs)\n",
        "\n",
        "# Clean and validate the data\n",
        "\n",
        "def clean_vfx_logs(df):\n",
        "    # Convert timestamp to datetime format\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "\n",
        "    # Drop data with missing or invalid data\n",
        "    df = df.dropna(subset=[\n",
        "        'timestamp', 'user_id', 'department','task_type', 'status', 'duration_sec'])\n",
        "\n",
        "    # Filter to known values\n",
        "    valid_statuses = ['in_progress', 'completed', 'failed', 'queued']\n",
        "    valid_departments = ['Lighting', 'Compositing', 'FX', 'Modeling','Rigging', 'Animation', 'Layout', 'Rendering']\n",
        "\n",
        "    df = df[df['status'].isin(valid_statuses)]\n",
        "    df = df[df['department'].isin(valid_departments)]\n",
        "\n",
        "    # Check if duration is a number val\n",
        "    df['duration_sec'] = pd.to_numeric(df['duration_sec'], errors='coerce')\n",
        "    df = df.dropna(subset=['duration_sec'])\n",
        "\n",
        "    return df\n",
        "\n",
        "df_clean = clean_vfx_logs(df)\n",
        "\n",
        "# Check to see tasks are within a given time and then categorize by length\n",
        "df_clean['long_task'] = df_clean['duration_sec'] > 7200  # > 2 hours\n",
        "df_clean['is_failed'] = df_clean['status'] == 'failed'\n",
        "\n",
        "# Count long and failed tasks\n",
        "long_task_count = df_clean['long_task'].sum()\n",
        "failed_task_count = df_clean['is_failed'].sum()\n",
        "\n",
        "print(f\"ðŸš¨ Long tasks: {long_task_count}, Failed tasks: {failed_task_count}\")\n",
        "\n",
        "# Create new data from the raw data (can be used for later use)\n",
        "\n",
        "df_clean['hour'] = df_clean['timestamp'].dt.hour\n",
        "df_clean['day'] = df_clean['timestamp'].dt.date\n",
        "\n",
        "# Summary table\n",
        "\n",
        "summary = df_clean.groupby('department')['duration_sec'].agg(\n",
        "    ['count', 'mean', 'median', 'max']\n",
        ").reset_index()\n",
        "summary.to_csv(\"plots/summary_by_department.csv\", index=False)\n",
        "\n",
        "user_summary = df_clean.groupby('user_id')['duration_sec'].agg(['count', 'mean', 'max']).sort_values(by='count', ascending=False)\n",
        "user_summary.to_csv(\"plots/user_summary.csv\")\n",
        "\n",
        "df_clean.to_csv(\"plots/cleaned_vfx_logs.csv\", index=False)\n",
        "summary.to_csv(\"plots/department_summary.csv\", index=False)\n",
        "\n",
        "df_clean[df_clean['is_failed']].to_csv(\"plots/failed_tasks.csv\", index=False)\n",
        "df_clean[df_clean['long_task']].to_csv(\"plots/long_tasks.csv\", index=False)\n",
        "\n",
        "\n",
        "# Final data visualization to be used for reports and further analyses\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot 1:Task Duration by Department\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df_clean, x='department', y='duration_sec')\n",
        "plt.title(\"Task Duration by Department\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plots/task_duration_by_department.png\")\n",
        "plt.close()\n",
        "\n",
        "# Plot 2:Number of Tasks Over Time\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_clean.groupby('day').size().plot(kind='line', marker='o')\n",
        "plt.title(\"Tasks Logged Over Time\")\n",
        "plt.ylabel(\"Number of Tasks\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plots/tasks_over_time.png\")\n",
        "plt.close()\n",
        "\n",
        "# Plot 3:Hourly Activity Heatmap by Department\n",
        "pivot = df_clean.pivot_table(index='hour', columns='department', values='log_id', aggfunc='count').fillna(0)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(pivot, cmap='YlGnBu', linewidths=.5, annot=True, fmt=\".0f\")\n",
        "plt.title(\"Activity Heatmap: Hour vs Department\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"plots/activity_heatmap.png\")\n",
        "plt.close()\n"
      ]
    }
  ]
}